save_path=./saved_models/exp1
command_line_args=Namespace(activation=2.0, episodes=200, func=<function args_train at 0x7ff2a5edeae8>, gamma=0.1, hidden_layers=3, hidden_units=40, init_weights=False, lamda=0.7, lr=0.1, model=None, name='exp1', save_path='./saved_models/exp1', save_step=0, seed=123, type='nn')
type=nn
hidden_units=40
init_weights=False
alpha=0.1
lamda=0.7
n_episodes=200
save_step=0
start_episode=0
name_experiment=exp1
env=backgammon-v0
restored_model=None
seed=123
eligibility=True
optimizer=None
modules=[TDGammon(
  (hidden): Sequential(
    (0): Linear(in_features=198, out_features=40, bias=True)
    (1): ReLU()
  )
  (hidden2): Sequential(
    (0): Linear(in_features=40, out_features=40, bias=True)
    (1): ReLU()
  )
  (hidden3): Sequential(
    (0): Linear(in_features=40, out_features=40, bias=True)
    (1): ReLU()
  )
  (output): Sequential(
    (0): Linear(in_features=40, out_features=1, bias=True)
    (1): Sigmoid()
  )
), Sequential(
  (0): Linear(in_features=198, out_features=40, bias=True)
  (1): ReLU()
), Linear(in_features=198, out_features=40, bias=True), ReLU(), Sequential(
  (0): Linear(in_features=40, out_features=40, bias=True)
  (1): ReLU()
), Linear(in_features=40, out_features=40, bias=True), ReLU(), Sequential(
  (0): Linear(in_features=40, out_features=40, bias=True)
  (1): ReLU()
), Linear(in_features=40, out_features=40, bias=True), ReLU(), Sequential(
  (0): Linear(in_features=40, out_features=1, bias=True)
  (1): Sigmoid()
), Linear(in_features=40, out_features=1, bias=True), Sigmoid()]
